# 渲染重要总结
#图像处理#

# OpenGLES 使用注意
1. shader文件加载时要把string转化为cstring。
2. shader语法问题是一个玄学问题，没有任何语法提示，也不能用中文。
3. iOS默认关闭了attribute传递数据，使用前要先enable对应的location。
4. UIImage的坐标原点在左上角，纹理坐标和CGImage原点在左下角，openGL处理原点是在中心，要处理图片的旋转问题，思路有：
	1. CG解压缩图片数据时通过transform进行旋转。
	2. 顶点着色器内对坐标进行上下交换。
5. 纹理激活数据绑定要和uniform传递数据的tag标记要对应，也就是加载到第几个问题上，就传递第几个纹理上的数据。

# 渲染3大步骤
1. 帧缓冲区和渲染缓冲区和可绘制表面的绑定。
2. 编译连接的到着色器program。
3. 准备数据并传递数据到program。
4. draw渲染。

# OpenGLES核心渲染流程理解
1. 初始化CAEAGLLayer、context并设置为当前上下文。
	1. 对CAEAGLLayer的绘制表面进行颜色格式设置或其他配置。
	2. 当前context的设置要在主线程设置保证和渲染是同一个线程。
2. 创建frameBuffer、renderBuffer缓冲区，建立renderBuffer 和CAEAGLLayer可绘制表面的绑定，并把渲renderBuffer附着到frameBuffer上进行管理。
3. 加载vshader和fshader并进行编译链接得到program。
	1. glAttachShader之后可以删除shader
	2. 链接完后需要检查program的可用性
4. 输入顶点和纹理坐标数据到glProgram的VSH对应location上。
	1. 先申请VBO，把顶点坐标数据拷贝到显存。
	2. 打开并设置attribute从显存中读取数据的方式。
5. 创建texture对象并输入纹理数据到glProgram的FSH对应sampler上。
	1. glActiveTexture激活纹理。
	2. glBindTexture绑定对应纹理。
	3. glTexImage2D载入图像数据到绑定的纹理上。
	4. glUniform1ui传递绑定的纹理到FSH对应的sanpler上。
6. 渲染texture纹理
	1. glEnable深度测试或者其他设置
	2. glClearColor清屏颜色
	3. 设置视口大小
	4. glDrawArrays开始OpenGLES绘制
	5. context.presentRenderbuffer把渲染绘制映射到屏幕上。

# Metal核心渲染流程
1. MTKView得到device，通过device创建一些列对象。
2. 加载shader创建renderPipeline。
3. 准备顶点纹理坐标数据到VBP，准备纹理像素数据到texture上。
4. 创建commandQueue，创建rederCommandEncoder传递数据。
5. 设置MTKView的代理回调，然后commandbuffer.present渲染数据到可绘制表面上完成显示。

总体和OpenGL类似，只是更加面向对象。

# 视频渲染处理相关总结
[OpenGL ES入门11-相机视频渲染 - 简书](https://www.jianshu.com/p/7da76246ce82)
[iOS渲染-将视频原始数据(RGB,YUV)渲染到屏幕上 - 掘金](https://juejin.im/post/6844903870657724429)

1. 高级点的采集视频渲染，只是预览而不需要修改处理可以直接用AVCaptureVideoPreviewLayer或者AVSampleBufferDisplayLayer进行渲染，简单方便。
2. 高级点的OpenGLES视频渲染，可以使用GLKView，是对CAEAGLLayer的封装，渲染通过setneeddisplay的drawrect进行，把图像转化为CGImage然后通过GLKTextureLoader送入到effect着色器上渲染，如果渲染视频的话就需要通过CG提供的方法把PixelBuffer先转化为CGImage对象。
3. 低级点的OpenGLES视频渲染，可以使用CAEAGLLayer，基本原理和图片渲染一样，核心是把SampleBuffer里的PixelBuffer提取出来转化为texture：
	1. 使用CoreVideo提供的方法可以快速的把PixelBuffer转化为对应的texture对象（YUV的话Y和UV要分别转化成texture），并且使用corevideo提供的cachebuffer进行buffer的缓存管理，然后把texture送入着色器进行渲染处理。
	2. 不使用CoreVideo的方法那就要自行创建texture对象，并且把PixelBuffer内的数据读出来存到texture上，再送入着色器处理，读取时要注意YUV的存储格式不同，读取的步长不同（主要是UV的存储是连续的还是单独分开的）
4. 也可以使用Metal进行视频渲染，核心筒OpenGLES渲染一样在于PixelBuffer到MTLTexture的转换，还是通过CoreVideo进行或者手动创建MTLTexture对象，再从PixelBuffer拷贝读取数据到texture对象上。

## 基本视频渲染方式
1. AVCaptureVideoPreviewLayer：直接拿capture session进行渲染展示
2. AVSampleBufferDisplayLayer：渲染展示采集的SampleBuffer
![](%E6%B8%B2%E6%9F%93%E9%87%8D%E8%A6%81%E6%80%BB%E7%BB%93/31F0A1ED-FA56-4741-B77D-2636F6342A53.png)

## Metal纹理渲染SampleBuffer
核心是通过CoreVideo提供的方法把采集的PixelBuffer转化为CVMetalTexture对象并通过TextureCache管理，再提取出MTLTexture对象进行渲染。
![](%E6%B8%B2%E6%9F%93%E9%87%8D%E8%A6%81%E6%80%BB%E7%BB%93/D27EFFD2-D268-4C6D-A644-B73EFC9DE72C.png)在MTKView的代理方法内进行MTLTexture 的渲染
![](%E6%B8%B2%E6%9F%93%E9%87%8D%E8%A6%81%E6%80%BB%E7%BB%93/F66978CB-0602-408B-99CF-BF3A47D878C3.png)

## GLKView渲染
CAEAGLLayer的高级的封装，通过drawrect完成渲染。
1. 首先将图片数据 -> CGImage对象。
2. 配置context环境，开辟VBO，打开Attrib传递顶点纹理坐标数据。
3. 通过GLKTextureLoader加载CGImage数据并绑定到指定texture2d0中。
![](%E6%B8%B2%E6%9F%93%E9%87%8D%E8%A6%81%E6%80%BB%E7%BB%93/2F789E51-9AA9-4CCA-BD9F-154EDD7A3670.png)
4. 直接调用view的display方法，就会进行GLKView的draw内，在draw里面进行gldraw的渲染。

## OpenGLES纹理渲染
核心是通过CoreVideo的方法把PixelBuffer转化为CVOpenGLESTexture对象并通过TextureCache管理，再提取出OpenGLES纹理送入着色器渲染。
1. 从采集的SampleBuffer拿到PixelBuffer原始数据。
2. 根据PixelBuffer的FormatType确定颜色存储格式，决定以何种格式渲染，通过CoreVideo把PixelBuffer转化为CVOpenGLESTexture，并绑定到对应的纹理target上（2D）。
	1. YUV格式的需要把Y和UV分量数据单独转换成OpenGLES纹理对象。
	2. BGRA大端可以直接转化为1个OpenGLES纹理对象。
3. 通过glUniform1i传递纹理数据到program对应的location上进行OpenGLES texture的渲染。
4. 片元着色器处理纹理时，要根据公式进行YUV到RGBA的颜色转换。
5. ::如果不使用CoreVideo作为中间对象的话::，就需要自行根据分辨率size创建OpenGLES Texture，然后单独的读取PixelBuffer上的YUV或者RGBA数据填充到Texture上，再送入着色器。
![](%E6%B8%B2%E6%9F%93%E9%87%8D%E8%A6%81%E6%80%BB%E7%BB%93/2C022864-8D45-4ACF-83FE-644FD8895AC0.png)
![](%E6%B8%B2%E6%9F%93%E9%87%8D%E8%A6%81%E6%80%BB%E7%BB%93/00657EC0-C08C-4DCD-9B3E-24B634DBC747.png)
![](%E6%B8%B2%E6%9F%93%E9%87%8D%E8%A6%81%E6%80%BB%E7%BB%93/BC47861F-7008-4419-9B38-8F4188C37AA4.png)
1. YUV因为存储的格式差异（UV一组还是UV分开），从PixelBuffer内读取像素数据时要分情况讨论读取，UV一组读取的步长为2。
2. BGRA大小为PixelBuffer像素宽高x4，直接读取复制就好。
