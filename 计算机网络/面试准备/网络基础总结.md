# 网络基础总结
#计算机网络/面试基础

<a href='%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93.pdf'>计算机网络面试题总结.pdf</a>

### 参考资料部分
[《TCP/IP详解 卷1：协议》在线整理版（含笔记）PDF免费分享 - 极客分享](https://www.geek-share.com/detail/2753158819.html)
[面试带你飞：这是一份全面的 计算机网络基础 总结攻略 - 掘金](https://juejin.im/post/5ad7e6c35188252ebd06acfa#heading-22)
[三天两夜肝完这篇万字长文，终于拿下了TCP/IP - 掘金](https://juejin.im/post/6850037269244575757#heading-26)

[5张图解：IP基础知识全家桶](https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/45-zhang-tu-jie-ip-ji-chu-zhi-shi-quan-jia-tong)
[40张图解：TCP三次握手和四次挥手面试题](https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/40-zhang-tu-jie-tcp-san-ci-wo-shou-he-si-ci-hui-shou-mian-shi-ti)
[30张图解：TCP重传、滑动窗口、流量控制、拥塞控制发愁](https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/30-zhang-tu-jie-tcp-zhong-chuan-hua-dong-chuang-kou-liu-liang-kong-zhi-yong-sai-kong-zhi-fa-chou)
[25 张图解：键入网址后，到网页显示，其间发生了什么 - labuladong的算法小抄](https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/25-zhang-tu-jie-jian-ru-wang-zhi-hou-dao-wang-ye-xian-shi-qi-jian-fa-sheng-le-shi-mo#yi-ge-shu-ju-bao-chou-bu-yao-lian-de-gan-shou)
[30张图解：HTTP常见面试题 - labuladong的算法小抄](https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/30-zhang-tu-jie-http-chang-jian-mian-shi-ti)

# TCPIP模型
### OSI7层，TCP/IP5层模型有哪些？作用？
1. 应用层(数据)：确定进程之间通信的性质以满足用户需要以及提供网络与用户应用。
2. 表示层(数据)：主要解决拥护信息的语法表示问题，如加密解密。
3. 会话层(数据)：提供包括访问验证和会话管理在内的建立和维护应用之间通信的机制，如服务器验证用户登录便是由会话层完成的。
4. 传输层(段)：实现网络不同主机上用户进程之间的数据通信，可靠与不可靠的传输，传输层的错误检测，流量控制等。
5. 网络层(包)：提供逻辑地址(IP)、选路，数据从源端到目的端的传输。
6. 数据链路层(帧)：将上层数据封装成帧，用 MAC 地址访问媒介，错误检测与修正。
7. 物理层(比特流):设备之间比特流的传输，物理接口，电气特性等 

5层：应用层、传输层、网络层、数据链路层、物理层

### TCP/IP模型各个层次的横向通讯理解？
下层为上层提供服务，比如：
1. 传输层是为应用层服务的，它通过IP地址加端口号进行的是应用到应用的通讯，或者说端到端的通信。
2. 网络层是为传输层服务的，它通过IP地址进行的是IP主机到IP主机间的通讯，通过逐跳转发，完成通信。
3. 物理链路层为网络层提供服务，是逐介质转逐介质的进行转发通讯，不同的介质都有它的地址，比如以太网通过Mac地址。

### TCP/IP模型各层使用的对应数据交换设备(交换机、路由器、网关) ？
1. 网关：用于应用层传输层间，以实现网络互连，是最复杂的网络互连设备，既可以用于广域网互连，也可以用于局域网互连。
2. 路由器：网络层（路由选择、存储转发）
3. 交换机：数据链路层、网络层（识别数据包中的MAC地址信息，根据MAC地址进行转发，并将这些MAC地址与对应的端口记录在自己内部的一个地址表中）
4. 网桥：数据链路层（将两个LAN连起来，根据MAC地址来转发帧）
5. 集线器（Hub）：物理层（纯硬件设备，主要用来连接计算机等网络终端）
6. 中继器：物理层（在比特级别对网络信号进行再生和重定时，从而使得它们能够在网络上传输更长的距离）

### 理解TCP/IP封装、分用思想？常见协议号？
封装：层层往下封包首部，上一层整体作为下一层的数据载荷。
分用：各层通过首部中的特殊协议号来实现对上层协议的分用。

端口号：http80、https443、SSH22。
IP协议号：ICMP1、tcp6、udp7。

# 物理链路层
[以太网协议](bear://x-callback-url/open-note?id=95DDBBF5-A435-40BF-A831-EBAB28E973D1-407-00004AB232041193)
### 理解最后以太网帧封包大小MTU为46-1500个子节是怎么来的？
各个链路上的延时，算法折中。在正常情况下，TCP 连接的 MSS 是 MTU - 40 字节，即 1460 字节；不过如果通信双方没有指定 MSS 的话，在默认情况下 MSS 的大小是 536 字节 。
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/F48CE838-5477-45F0-8AA1-BB3609CA2D2F.png)

### 理解为什么有线比无线快的原因？
无线实际上共享同一介质，半双工。

### 理解交换机如何通过自学原理根据Mac地址进行转发？
广播。主机通过交换机A某个接口发出了一个帧给B后，交换机内部会提取源Mac地址和入接口产生一个mac地址条目添加到一张表里。这时候查表发现表里没有目地Mac地址条目信息，交换机就会向它的广播域（除了入接口以外的全部接口）发送，这时候B收到后会回帧，CD直接丢掉，B回帧后交换机又会记录B的源Mac地址信息添加进表里，下一次有任何发给B的帧就能直接发送给B了，而不用进行广播。

### 以太网帧的头部格式？
源+目mac地址+网络层协议号。

### 理解环回口机制（127.X.X.X）？
一般用于在同一机器进行tcp/ip通信。目的地址为环回接口（本机地址）的数据据一般不会出现在网络上（如果有怪异的实现，也没办法）。
理论上说传输层检测到目的地址为环回地址时，可以省去部分传输层和全部网络层及其以下的逻辑操作，但大部分产品还是完成了传输层与网络层的所有过程，只是当IP数据报离开网络层时又直接返回给了自已而不会进行以太网封包。

[ARP协议](bear://x-callback-url/open-note?id=76DD11E4-63A3-4891-8776-8AC05A2D0F0B-407-00004EBA759FCF5E)
### ARP（IPv4）协议、ICMPv6的作用？ARP不安全的原因？
介于网络和链路层间，提供IP地址到MAC地址的映射。
1. 缓存：主机的地址映射是基于高速缓存的，动态更新的。地址刷新是有时间限制的。 可以通过下次更新之前修改计算机上的地址缓存，造成拒绝服务攻击或者 ARP 欺骗。
2. 广播：攻击者可以伪装 ARP 应答。
3. 不安全：ARP 应答没有认证都是合法的。可以在不接受到请求的时候就发出应答包。 

### 点对点网络链路（IPSec隧道、PPP）使用 ARP吗? 
不需要地址解析，也就不需要ARP。

# 网络层
[IP协议](bear://x-callback-url/open-note?id=0AFC6A96-DCDB-4D83-9AAB-2D6D07FDE646-407-00008303049868BF)
### 理解数据链路和网络层之间的关系？
数据链路层完成数据的实际传送，网络层通过路由器安排在不同数据链路层间通讯传递数据时选择哪种链路路径。

### 理解IP协议不可靠、IP数据包无序？
1. IP协议不可靠：指的是不能保证数据报能成功地到达目的地。 发生错误时候，丢弃该数据包，发送 ICMP 消息给信源端。 
2. IP数据包无序：IP 不维护关于后续数据报的状态信息。体现在，IP 数据可以不按顺序发送和接收。A 发送连续的数据报，到达 B 不一定是连续的， 来回路由选择可能不一样，路线也不一样，到达先后顺序也不一样。 

### 理解IP首部格式（20个bety），哪些字段构成？
1. 基本相关：源、目IP地址。
2. 分片相关：总包长度、片偏移（单位是8）、标志位。
3. 传输相关：TTL、传输层协议号等。

### IP首部ECN位在TCP上显示拥塞通告的大致原理？
发IP包首部里发10->路由器改为11->收TCP头部ECE置为1->发TCP头部CWR置为1 。

**详细理解：**
牵扯到TCP和IP，TCP首部里面有CWR、ECE位。
首先在TCP握手的时候会协商2端是否都支持ECN位。
当一个支持ECN的10包穿过某个路由并遇到拥塞时，路由器将这个包的ECN位改为11，标识发生了拥塞，接收端收到后看到ECN为11则通过设置TCP头部ECE标志位为1回一个包给源端告诉它IP告诉我这个包差点被丢了，只是路由器放过了，你要发慢一点。
源端收到TCP首部ECE标志位为1的包则知道网络中出现了拥塞，TCP会调低滑动窗口，降低发送速度，成功降低后会回一个包并把TCP首部CWR标志位置为1告诉接收端我已经慢了。

### IP 首部校验和怎么计算的，知道与 ICMP，IGMP，TCP，UDP 的首部校验和的区别是它只针对首部校验? 
1. 对首部中每个 16 位比特进行二进制反码求和，结果存在检验和字段中。
2. 收到一份 IP 数据包后，同样对首部中每个 16位比特进行二进制反码求和。
最后结果全为 1，表示正确，否则表示错误。

[IP分片](bear://x-callback-url/open-note?id=B467E5BA-2C3B-463C-A20C-61F7B38560E5-407-00008BAE21939D9A)
### IP分片的大小和什么有关？分片在什么时候才进行重组？如何重组？
IP分片的大小和MTU大小有关，每个链路可能不同，所以分片也可能发生在中间路由器上。
IP分片的组装只有到达目的地后（收端）才会组装。
重组依据是每个分片IP首部中的总长度和偏移信息。

### 理解IP分片的效率低的原因？理解TCP如何通过MSS避免IP？
丢一片上层TCP就需要整个重发。比如TCP 协议为了保证可靠性， 在握手时通过2边MTU协商出 MSS（MTU-40bety） 并根据 MSS 分段应用层数据包，避免 IP 协议对数据包进行分片。因为 IP 层对数据包的分片对上层是透明的，如果协议不根据 MTU 做一些限制，那么 IP 协议的分片会导致部分数据包失去传输层协议头，一旦数据包发生丢失就只能丢弃全部数据。
[为什么 TCP/IP 协议会拆分数据 - 面向信仰编程](https://draveness.me/whys-the-design-tcp-segment-ip-packet/)

### 理解IP分片的过程，比如一个IP包附载1980bety的数据依次传过R1、R2路由器，2个路由器MTU依次为1500、1000怎么分包?
IP首部里片偏移单位是8bety，所以分片的数据包负载部分除最后一片大小必须是8的倍数。
R1：(R1的1500MTU-20包头)/8，整数为185，所以经过RI时分成2个包，一个负载185*8=1480数据，一个负载500数据。
R2：(R2的1000MTU-20包头)/8，整数为122，所以经过R2时分成2个包，一个负载122*8=976数据，一个负载1480-976=504数据。

### 理解Path MTU探测的原理？
首先把IP包标志位置置为1表示不能分片，发送一个1500大小的探测包，如果经过路由MTU比它小，会回一个错误包附带MTU信息，拿到这个信息更新发送包的大小，如果还是收到错误包，则继续根据MTU信息更新包大小，直到数据成功发送，就能获取到Path MTU。

### ICMP协议的理解？Ping的过程？
1. 网络和传输之间的辅助控制协议，2种查询报文，5种差错控制报文。
2. 差错报文是用来简单的报告错误的，至于对于错误怎么处理是高层协议的职责， 同时,差错报文总是发送给最初的数据源，查询报文总是成对出现。
3. ping命令基于ICMP协议，发送一个 ICMP包，可达时目标主机会回送一个可达的ICMP包。

# 传输层
### TCP/UDP对比
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/D46AE7C0-1A10-41E9-BC82-E7019B1DE206.png)

### UDP的首部格式？
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/7EDC0379-C904-4004-A8A7-A55A269AD183.png)
源目的端口号、数据长度、校验和。

### UDP特点的理解？
1. 无连接：不需要三次握手，四次挥手建立连接，可以随时进行数据发送。
2. 不可靠：因为IP层就不可靠，UDP只管发，不管可靠，如果需要可靠则要在应用层处理。
3. 面向报文：应用层交给UDP多长的报传输层头部就照样发送，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP包太小。UDP对应用层交下来的报文，既不合并，也不拆分。

### 理解UDP广播和组播？组播为什么比广播好？
TCP面向连接，没有广播和组播。
因为从数据帧过滤看，组播在数据链路层发现自己不在这个组播地址里，则丢掉这个数据帧。如果是广播的话会交给上层IP层，一般IP层不会做什么数据过滤，会继续往上交给UDP，UDP通过判断是否有应用监听这个广播端口号才能决定是否丢弃，如此浪费了很多资源。

[TCP协议](bear://x-callback-url/open-note?id=86C21946-5F98-4B1B-8113-0AFD33DB754A-407-00008F581A631B2D)

### TCP首部构成？
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/8BC677E5-C326-450A-9C63-AB9AE8FECFE4.png)
1. 基本相关：源、目端口号
2. 可靠相关：序列号位、ACK号位
3. 流控相关：窗口大小

### TCP的特点理解？
1. 面向连接：传输开始前，需要三次握手建立连接。传输结束后，需要四次挥手释放连接。
2. 可靠：通过序列号与确认应答以及重发机制保证可靠，通过用塞控制、滑动窗口流控机制提高可靠性。
3. 面向字节流：
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/05EDB72B-66DE-4A88-81D9-F7AD44BE07E5.png)
虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送（MSS：TCP一次传输发送的不被IP分片的最大数据段长度）。

### 理解序列号如何产生？
由操作系统内核算法随机生成的。

### TCP发包和滑动窗口单位MSS的理解？一般为多大？
MSS：不被IP分片的最大消息长度，大小MTU1500-20-20，实际大小确定是握手时2边协商。

### 理解滑动窗口的过程，特点和主要作用？
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/9E3498D0-E502-47DC-940B-0DFD3B9ABFFD.png)
窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据，如果按期收到确认应答，此时数据就可以从缓存区清除，收方缓冲区会不断变化，在ACK中通告给发方（对应就是Socket缓冲区）。

提高发送速度：同时发而无需发一个收到ack再发。
接收方的流控机制：接收方在ACK中通告自己的窗口大小，避免拥塞。
快速重传提高重传效率：发送方收到3个重复ACK，直接重传而不必等到超时重传。

### 发送方如何最终确认发送数据的大小？
min（发、收窗口大小，用塞窗口大小，操作系统调度）

### TCP 是如何解决窗口关闭时，潜在的死锁现象呢？
如果接收方缓存满了后通告给发送方的窗口大小为0时，发送方会先停止发送，然后TCP 会启动为每个连接设有的一个持续定时器，
接受方：间隔一段时间缓存空闲出来的时候，发送一个窗口更新的通知包给发送方，去更新窗口大小。
发送方：但是这个包也可能会丢，所以还需要发送方也间隔一段时间就发送一个窗口探测的数据包过去，询问接收方的窗口大小。

### 糊涂窗口问题怎么解决（接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小）？
1. 让接收方不通告小窗口给发送方
2. 让发送方避免发送小数据（Nagle）


### 拥塞控制的过程理解？
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/C5C2B317-E963-4D68-A3EB-729E1054286B.png)
1. 慢启动阶段：一开始不了解网络情况的环境系，发送方选取一个MSS（TCP一次传输发送的不被IP分片的最大数据段长度），作为拥塞窗口cwnd的大小，在每一次确认应答后指数增大窗口大小。
2. 拥塞避免阶段：其实慢启动还维护了拥塞门限窗口大小，在拥塞窗口小于门限窗口大小时，还是处于慢启动环节，一旦大于临界值窗口大小，开始进入拥塞避免。RFC建议拥塞避免环节，无论一个RTT（发送方发出到接收到1个数据包的往返时延）可以收到多少个ACK，每一次确认都只新增1个MSS，呈线性关系增长，避免快速的触碰到网络拥塞点。
3. 碰到拥塞点后：
	1. 快重传和快恢：::快重传算法要求接收方收到一个失序的报文段后立刻发出重复确认，而不要等待自己发送数据时才进行捎带确认。::当收到3个重复ACK后，拥塞窗口大小不会直接降为1进入慢启动，而是在更新后的慢启动阀值基础上+3，直接进入拥塞避免。
	1. 超时重传：发送的数据迟迟收不到ack，就会触发超时重传机制，会把用塞窗口直接降为1，重新慢启动发送。

### 快速重传为什么是3个重复ACK？
3个一定能保证是因为丢包产生。因为两次重复 ACK肯定是乱序造成的，丢包肯定会造成三次重复 ACK [TCP 快速重传为什么是三次冗余 ACK，这个三次是怎么定下来的？ - 知乎](https://www.zhihu.com/question/21789252)

### 快速重传比超时重传效率高的原因？
因为直接进入用塞避免阶段，并且还可以通过选择确认SACK包，只重传丢失的那部分数据。

### 慢启动到拥塞避免的临界值大小在什么时候确定？多大？
发生超时重传或者快重传之后，大小为上一次最大用塞窗口一半。

### 理解延迟确认应答和捎带应答这2种提高网络利用率的机制？
延迟确认应答：等一会再回复ACK，使通告的窗口大一点。
捎带应答：交互式数据流中，接收方准备好要发的时候才同时把ack和准备好的数据包一起通过一个包发过去。

[TCP 连接建立和终止](bear://x-callback-url/open-note?id=EB751F3F-50FE-4753-8F42-0E2C35B4102F-407-0000CEDE0E51D8C4)
### 理解TCP3次握手建立连接的过程（协商MSS、）？
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/4AE48E87-4958-4304-9469-1D0FC32E5077.png)
1. 第一次握手：客户端将标志位SYN置为1，随机产生一个值seq=J，并将该数据包发送给服务器端，客户端进入SYN_SENT状态，等待服务器端确认。
2. 第二次握手：服务器端收到数据包后由标志位SYN=1知道客户端请求建立连接，服务器端将标志位SYN和ACK都置为1，ack=J+1，随机产生一个值seq=K，并将该数据包发送给客户端以确认连接请求，服务器端进入SYN_RCVD状态。
3. 第三次握手：客户端收到确认后，检查ack是否为J+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=K+1，并将该数据包发送给服务器端，服务器端检查ack是否为K+1，ACK是否为1，如果正确则连接建立成功，客户端和服务器端进入ESTABLISHED状态，完成三次握手，随后客户端与服务器端之间可以开始传输数据了。

### TCP为什么3次握手而不是2次？
1. 第一种理解：2次时如果server收到的syn是由于网络延迟后接收到的，而client此时并没有连接的需求，server还要去维护这个连接导致资源浪费。用3次则client向server的syn发出确认ack表明自己有连接需求，同时如果server收不到确认，就知道client并没有要求建立连接。
2. 第二种理解：互相交换收发双方的收发能力。

### 2次Fin交换断开连接的过程？（3次挥手还是四次挥手主要取决于场景，server使用延迟确认，也就是Server对Client的FIN报文的确认延迟到和Server的FIN一起发也是可以的，也能保证全双工下2端正常断开。）
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/C80E66D1-CF94-483B-BD40-8D6601C84A35.png)
1. 第一次挥手：客户端发送一个FIN=M，用来关闭客户端到服务器端的数据传送，客户端进入FIN_WAIT_1状态。意思是说”我客户端没有数据要发给你了”，但是如果你服务器端还有数据没有发送完成，则不必急着关闭连接，可以继续发送数据。
2. 第二次挥手：服务器端收到FIN后，先发送ack=M+1，告诉客户端，你的请求我收到了，但是我还没准备好，请继续你等我的消息。这个时候客户端就进入FIN_WAIT_2 状态，继续等待服务器端的FIN报文。
3. 第三次挥手：当服务器端确定数据已发送完成，则向客户端发送FIN=N报文，告诉客户端，好了，我这边数据发完了，准备好关闭连接了。服务器端进入LAST_ACK状态。
4. 第四次挥手：客户端收到FIN=N报文后，就知道可以关闭连接了，但是他还是不相信网络，怕服务器端不知道要关闭，所以发送ack=N+1后进入TIME_WAIT状态，如果Server端没有收到ACK则可以重传。服务器端收到ACK后，就知道可以断开连接了。客户端等待了2MSL后依然没有收到回复，则证明服务器端已正常关闭，那好，我客户端也可以关闭连接了。最终完成了四次握手。

### 为什么2次Fin交换？
因为TCP是全双工的。当被动的一方接受到连接断开消息时，它有可能还在发送数据。这时候比较高效的做法是先发送一个断开确认消息回复主动断开的一方，我已经收到了你的连接断开消息，但是我有可能还需要发送一些数据，请等待。当所有数据发送完成之后再发送最终的连接断开消息给主动方，然后等待断开的回复，收到回复后关闭链接。

### 为什么TIME_WAIT状态需要经过2MSL(2倍最大报文段生存时间)才能返回到CLOSE状态。
保证最后一次挥手没有丢包的情况，连接可以安全断开。因为如果有丢包的话，在2MSL（最后一次ACK+重发的FIN）时间内肯定会收到一个重发的FIN包文。超过这个时间后操作系统才会释放占用的资源和端口号。

### 如何处理TCP粘包、分包问题
使用TCP协议做网络模块开发时，由于TCP本身的机制，如果发送的数据很小，那么会自动把一些小的数据合并在一起发送出去，但是接收端就没办法理解数据包并自行分开它，这就是粘包现象。而当一次发送的数据又过长的时候，TCP就会把该数据分成几部分发送出去，每次接收方就只会接受部分的数据，这就是分包现象。由于粘包和分包现象是在传输层发生的，我们只能在应用层想办法解决，处理粘包和分包有很多方法，这里介绍几种常见的方法。

1. 第一种方法，类似Http contentLength，是在每个数据包前面加上该数据包的长度，作为该数据包的包头，当收到消息包时，先读取消息包头，得到消息包的长度，再根据这个长度去缓冲区读取对应长度的字节。
2. 第二种方法，类似Http 分块传输，是在每个消息包的头部或尾部加上一个标识符，这个标识符不能是常用的字符，比如可以使用‘￥’这类平时不会出现在消息体中的字符，将它作为消息包界限，接收端在收到消息后就能根据这个界限方便的去做处理。

### TCP-Alive的理解？
传输层面上的保活机制，确定对端存活状态（检查半断开）。

# 应用层
[HTTP和HTTPS详解](https://juejin.im/post/6844903604868874247)

### HTTP特点？
HTTP是一种位于应用层的文本传输协议，它的本质是一组协议规范，主要解决互联网应用间的通信问题，主要包含定义了客户端和服务端间通信的报文格式和请求响应方案以及对于传输层协议TCP的连接管理，特点如下：
1. 无连接：对于HTTP1.1来讲默认是持久的长连接，下次的事务处理还是在这条连接上。
2. 无常态：对于事务处理没有记忆能力，一般过程cookie和Session来解决。

### 理解HTTP持久连接？
HTTP/1.1起，默认使用长连接，通过首部字段
```
Connection: Keep-Alive
Keep-Alive: max=5, timeout=120 
```
> TCP Keep-Alive 是用于server检测client连接的死活，而HTTP应用层心跳机制除了检测连接死活外还检测在应用层面通讯双方的存活状态。  

### 持久连接如何判定传输结束？
1. 首部字段Conent-Length
正常情况下是判断传输数据是否达到了Content-Length指示的大小
2. 首部字段Transfer-Encoding分块传输编码
动态生成的文件没有固定大小，这时可以使用分块传输编码来判断传输是否结束。分块传输编码把报文分割为若干个大小已知的块，块之间是紧挨着发送的，这样就不需要在发送之前知道整个报文的大小了，chunked编码的数据在最后有一个空chunked块，表明本次传输数据结束。
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/1130EFB4-6FA0-44DB-BA2A-43A3DD8BFF3E.png)

### HTTP报文结构
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/D4717DB5-4E23-48A2-9F90-87A4914EECD4.png)
1. 对报文进行描述的起始行(start line)
2. 包含属性的首部(header)块
3. 以及可选的、包含数据的主体(body)部分

### 请求报文结构？
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/B8B03CA3-5F7D-490D-B44B-7337CE395505.png)
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/62426346-6ACF-4749-AF35-048E0E6EBF99.png)

### 响应报文结构？
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/56ACE43E-6091-4F8D-B1D7-A9FC04844EA5.png)
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/5FF5DCD4-B14C-4B0D-9416-152144B2A471.png)

### HTTP状态码
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/930C7ABA-5454-4F33-B70B-726369FE448E.png)

### HTTP请求方案？
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/71C67B28-F933-4D52-AB39-E4FA7C7BBE05.png) 
### GET和POST的区别
先说HTTP本身都是基于TCP/IP的，它只是一个文本传输协议，约定双方的请求和响应规则，让请求更加有语义，本质都是一坨文本。你也可以不按照它的规范，约定自己的规则，只要双方能互相识别并通信即可。

::按照RFC标准规范，从语义上讲GET/POST的主要区别：::
1. GET一般用来获取资源或数据，POST用来处理资源或数据
2. GET是安全的、具备幂等性、可缓存的
3. POST则相反是不安全的、不具备幂等性、不可缓存的

**安全的理解**
所有的请求操作不会对server服务端产生任务状态变化和副作用。
**幂等性的理解**
如果一个事务，不管是执行一次还是很多次，得到的结果都相同，这个事务就是幂等的。实现者们可以认为 GET、HEAD、PUT、DELETE、TRACE 和 OPTIONS 方法都共享这一特性。 
**可缓存的理解**
请求的数据在本地以副本的形式保存，当 Web 请求抵达缓存时，如果本地有“已缓存的”副本，就可以从本地存储设备而不是原始服务器中提取这个文档。

其次web端浏览器厂商不同、可能存在一些约定限制：
1. GET产生一个TCP数据包，POST产生两个TCP数据包（先发送header，服务器响应100 continue，浏览器再发送data。）
2. GET在浏览器回退时是无害的，而POST会再次提交请求。
3. GET产生的URL地址可以被Bookmark，而POST不可以。
4. GET请求会被浏览器主动cache，而POST不会，除非手动设置。
5. GET请求参数会完整保留在浏览器历史记录里，而POST中的参数不会保留。
6. GET请求在URL中传送的参数是有长度限制的，而POST么有。

### 请求体常见格式Content-Type？
1. application/x-www-form-urlencoded：原生 form 表单提交形式，默认为这个，提交的数据按照 key1=val1&key2=val2 的方式进行编码。
```
POST  HTTP/1.1
Host: www.demo.com
Cache-Control: no-cache
Postman-Token: 81d7b315-d4be-8ee8-1237-04f3976de032
Content-Type: application/x-www-form-urlencoded

key=value&testKey=testValue
```
2. multipart/form-data：上传文件、二进制数据、非ASCII数据使用，用boundary作为间隔标识。
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/DA3F5672-4B34-4F3B-B6E0-4605C42AD65C.png)
用boundary作为间隔标识
3. application/json：用charset标记编码方式
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/5C0A4B81-F4B3-47BC-8AE6-8FCDA4BC067E.png)

### HTTP各版本特点？

HTTP/1.1 ：
1. 默认长连接的方式：同一条TCP连接上完成数据收发，提高效率。
2. 管道（pipeline）传输：在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

HTTP/2 ：基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。
1. 头压缩：如果你同时发出多个请求，他们的头是一样的或是相似的，这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。
2. 二进制格式传输：HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，虽然对人不友好，但是对计算机非常友好，直接解析二进制报文，增加了数据传输的效率。
3. 多路复用：移除了 HTTP/1.1 中的串行请求，一个连接中并发多个请求或回应，而不用按照顺序一一对应，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，大幅度提高了连接的利用率。
4. 数据流：HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应，客户端还可以指定数据流的优先级。优先级高的请求，服务器就先响应该请求。

HTTP/3 ：解决HTTP/2 中复用一个 TCP 连接后，下层的 TCP 不知道上层有多少个 HTTP 请求的，所以一旦发生了丢包现象，就会触发 TCP 的重传机制，就会阻塞住所有上层HTTP 请求的问题。
1. UDP+QUIC：去掉了TCP，通过UDP进行传输，QUIC保证可靠。

# HTTPS
### 理解HTTPS？
HTTPS = HTTP+SSL/TLS（网络安全层，位于TCP之上）
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/4CB60080-35BD-4F07-8773-9A745D3A6EF7.png)

TLS的基本工作方式是，客户端使用非对称加密与服务器进行通信，实现身份验证并协商对称加密使用的密钥， 然后对称加密算法采用协商密钥对信息以及信息摘要进行加密通信，不同的节点之间采用的对称密钥不同，从而可以保证信息只能通信双方获取。

### HTTPS和HTTP的区别？
安全：HTTP属于明文传输，HTTPS基于SSL进行加密传输。
端口号：HTTP端口号为80，HTTPS端口号为443。

### HTTPS为什么安全？
HTTPS协议的主要功能基本都依赖于TLS/SSL协议，TLS/SSL的功能实现主要依赖于三类基本算法：散列函数 Hash、对称加密和非对称加密，其利用非对称加密实现身份认证和密钥协商，对称加密算法采用协商的密钥对数据加密，基于散列函数验证信息的完整性。

在建立TCP连接后客户端和服务器就会初始化 SSL 层，对加密参数进行沟通，SSL初始化完成后，客户端就可以将加密请求报文发送给安全层了。它的安全性包括如下：

* 校验双方身份的真实性：证书
* 数据的保密性：对称和非对称加密
* 数据的完整性：哈希算法提取摘要、用私匙对摘要加密作为数字签名发送

### HTTPS建立连接和通信过程（TCP3次握手连接之后）？
[HTTPS篇之SSL握手过程详解 | Razeen`s Blog](https://razeencheng.com/post/ssl-handshake-detail)
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/6DE71F1C-29D5-476B-88BC-F1CFA647966E.png)
1. 客户端向服务器发送Client Hello，告诉服务器我支持的协议版本、加密算法等信息。
2. 服务器收到响应，选择双方都支持的协议套件、加密算法，向客户端发送Server Hello，同时服务器也将自己的证书发送到客户端(Certificate)。
3. 客户端自己生产对称密钥，通过公钥加密对称密钥，将加密后的对称密钥发送给服务器 (Client Exchange)。
4. 服务器用自己的私钥解密加密的对称密钥。
5. 随后双方通过这个对称密钥进行安全的数据通信。

### 如何保证server公钥的合法性
证书由server去CA机构申请，CA本身也有一对公钥和私钥，CA会用CA自己的私钥对要进行认证的公钥进行非对称加密并签名，设备的操作系统中都会内置100多个全球公认的CA公钥，然后client会对证书做校验。

A.服务方S向第三方机构CA提交公钥、组织信息、个人信息(域名)等信息并申请认证;
B.CA通过线上、线下等多种手段验证申请者提供信息的真实性，如组织是否存在、企业是否合法，是否拥有域名的所有权等;
C.如信息审核通过，CA会向申请者签发认证文件-证书。 证书包含以下信息：申请者公钥、申请者的组织信息和个人信息、签发机构 CA的信息、有效时间、证书序列号等信息的明文，同时包含一个签名; 签名的产生算法：首先，使用散列函数计算公开的明文信息的信息摘要，然后，采用 CA的私钥对信息摘要进行加密，密文即签名;
D.客户端 C 向服务器 S 发出请求时，S 返回证书文件;
E.客户端 C读取证书中的相关的明文信息，采用相同的散列函数计算得到信息摘要，然后，利用对应 CA的公钥解密签名数据，对比证书的信息摘要，如果一致，则可以确认证书的合法性，即公钥合法;
F.客户端然后验证证书相关的域名信息、有效时间等信息;
G.客户端会内置信任CA的证书信息(包含公钥)，如果CA不被信任，则找不到对应 CA的证书，证书也会被判定非法。
在这个过程注意几点：
A.申请证书不需要提供私钥，确保私钥永远只能服务器掌握;
B.证书的合法性仍然依赖于非对称加密算法，证书主要是增加了服务器信息以及签名;
C.内置 CA 对应的证书称为根证书，颁发者和使用者相同，自己为自己签名，即自签名证书（为什么说”部署自签SSL证书非常不安全”）
D.证书=公钥+申请者与颁发者信息+签名;

### HTTPS查尔斯抓包原理
原理上来讲还是类似中间人攻击，但是这个中间人是我们自己设置的。
Charles作为“中间人代理”拿到了服务器证书公钥和协商的对称密钥。

::前提是客户端选择信任并安装Charles的CA根证书::（当你安装了该根证书之后，该证书机构颁发的其他证书默认都会被你的系统所信任，实际抓包过程中会动态制作证书）

1. Charles拦截客户端的请求，伪装成客户端向服务器进行证书的请求。
2. Charles拦截服务器的证书请求响应，获取服务器证书公钥，然后自己动态制作一张证书，将服务器证书替换后发送给客户端。（这一步，Charles拿到了服务器证书的公钥）
3. 客户端接收到“服务器”（实际上是Charles）的证书后，生成一个对称密钥，用Charles的公钥加密，发送给“服务器”（Charles）
4. Charles拦截客户端的响应，用自己的私钥解密对称密钥，然后用服务器证书公钥加密，发送给服务器。（这一步，Charles拿到了对称密钥）
5. 服务器用自己的私钥解密对称密钥，向“客户端”（Charles）发送响应
6. Charles拦截服务器的响应，替换成自己的证书后发送给客户端
7. 至此，连接建立，Charles拿到了 服务器证书的公钥 和 客户端与服务器协商的对称密钥，之后就可以解密或者修改加密的报文了。

### 防止HTTPS抓包的理解？
1. 判断是否设置了代理。
2. 双向证书的锁定验证：牺牲了灵活性，证书变化，客户端必须升级。

> 绝对的防止抓包是不可能的，只是可以进行一些限制，保障数据安全的最好方式就是对数据本身进行加密，即使抓包也无法获得具体数据。  

### HTTPS接入优化（CDN）？
HTTPS 增加的延时主要是传输延时 RTT，RTT 的特点是节点越近延时越小，CDN 天然离用户最近，因此选择使用 CDN 作为 HTTPS 接入的入口，将能够极大减少接入延时。CDN 节点通过和业务服务器维持长连接、会话复用和链路质量优化等可控方法，极大减少 HTTPS 带来的延时。


# DNS解析
DNS是域名到IP地址的映射，DNS解析使用UDP数据报，端口号53，并且采用明文传输的方式。客户端在向服务端发送请求时，会先将域名到DNS服务器映射出IP地址，然后再访问。

### DNS解析两种查询方式？区别？
1. 递归查询：不断地自下而上遍历解析，“我去给你问一下”的方式，如果没有，它会自动向上去查询，最后返回一个准确的查询结果。
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/3D461952-9B69-474C-B85F-BEABD7513D51.png)

2. 迭代查询：迭代查询是 “我告诉你谁可能知道”的方式，不直接返回查询结果，返回一台可能知道的DNS服务器地址。

### DNS劫持解决方案？
使用HTTP协议向DNS服务器80端口进行请求
> DNS劫持和HTTP没有关系，因为发生在HTTP建立连接之前。  

# 密码学
### 非对称加密算法（HTTPS连接建立的过程使用）
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/3B7912CC-F82F-4671-AF52-961F158B95AB.png)
需要有2个密钥，公钥和私钥。公钥向所有人公开，私钥不公开。用公钥加密的数据只有私钥才能解密，用私钥加密的数据只有公钥才能解密。

**优点：安全**
**缺点：速度慢，非常耗时**

> 因为这种特性，非对称加密算法可以用来校验数字签名。  
> 常见的非对称加密算法有RSA、DSA等。  

### 对称加密算法（HTTPS连接建立后通信时使用）
![](%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E6%80%BB%E7%BB%93/90404710-FC6D-4780-9AC6-9CBEC120ACA4.png)
加密和解密使用相同的密钥。
**优点：加密速度快。**
**缺点：任何一方都可能泄露密钥，如果泄露则不安全**

> 常见的对称加密算法有AES、DES等。  

### 线性散列算法加密
MD5、SHA1、HMAC。具备单向的算法不可逆性（被MD5加密的数据不能被解密）。MD5加密后的数据长度要比加密数据小的多，且长度固定，且加密后的串是唯一的。

**适用场景**：常用在不可还原的密码存储、信息完整性校验等。

### SSH远程免密安全登录原理？
安全上和HTTPS类似，只是没有CA的认证参与，共钥直接给对端（类似github直接复制到后台），然后通过非对称加密协商确认身份实现免密登录。

# 其他
### session和cookie区别？
1. 存储位置上cookie是C端，而session是S端
2. 安全性上session相对安全。
3. 有效期上Cookie 可设置为长时间保持，Session 一般失效时间较短（30分钟），客户端关闭或者 Session 超时都会失效。

### 分布式 Session的问题？
为了可以支撑更大的流量，以及服务器的负载均衡。后端往往需要多台服务器共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题，一般解决方案如下：

1. 服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。
2. Session 复制，任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。
3. 共享 Session，服务端无状态话，将用户的 Session 等信息使用缓存中间件来统一管理，保障分发到每一个服务器的响应结果都一致。

### Token机制的理解？
一种身份验证机制，主要是用来解决基于服务器的Session状态验证中的问题，比如内存开销、跨域资源共享、跨站请求伪造等。

HTTP请求都是以无状态的形式对接，即HTTP服务器不知道本次请求和上一次请求是否有关联。所以就有了Session的引入，即服务端和客户端都保存一段文本，客户端每次发起请求都带着，这样服务器就知道客户端是否发起过请求。但这样也会导致客户端频繁向服务端发出请求数据，服务端频繁的去数据库查询用户名和密码并进行对比，判断用户名和密码正确与否，而Session的存储是需要空间的，频繁的查询数据库给服务器造成很大的压力。

token本质和session id一样，每次C端请求带上token来表明自己的合法地位，S端进行验证。特点是会进行加密防止伪造，并且无状态化（不会将登录信息放在Session中，相当于只要你拿到了这个令牌，有了权限就允许进行操作而无关登录状态）